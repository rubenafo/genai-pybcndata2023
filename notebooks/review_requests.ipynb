{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208ce981-227a-4a03-9d76-0b1b17677dd2",
   "metadata": {},
   "source": [
    "# Workshop Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5b6cc606-9c18-47a7-aa2b-69374b220fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/site-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f505e37c-819a-4a4a-b157-e7e94216a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import loader\n",
    "from queries import Queries\n",
    "from queries import Prompts\n",
    "import pandas as pd\n",
    "\n",
    "# This is our email datasource\n",
    "emails_ds = loader.load_dataset()\n",
    "userinfo = pd.DataFrame(columns=[\"sentiment\", \"loan_qty\", \"sender\", \"motivation\", \"esg\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5758dca-1e19-47c7-9dd1-ce97e333347f",
   "metadata": {},
   "source": [
    "# The stuff ResponsibleLending has to deal with\n",
    "\n",
    "Take a look to the sample dataset of emails recieved by ResponsibleLending by running **view_dataset** notebook under this folder.    \n",
    "There is a mix of senders and motivations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f951c43-86a2-40df-abaa-1255874c42d1",
   "metadata": {},
   "source": [
    "# Exploring sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554244b2-f407-4731-9edf-27bd6a916150",
   "metadata": {},
   "source": [
    "LLM models are already pretrained with large corpus of data so some functionality is available out of the box.\n",
    "\n",
    "* In this example we'll be using Falcon-7B-instruct (https://huggingface.co/tiiuae/falcon-7b-instruct)\n",
    "* Falcon-40B is now available in HuggingFace Inference API: https://huggingface.co/tiiuae/falcon-40b\n",
    "\n",
    "If you want to try Falcon-40B you can do so by changing the model parameter in the run_query method:\n",
    "```python\n",
    "def run_query(payload={}, model=\"tiiuae/falcon-40b\"):\n",
    "```\n",
    "\n",
    "In the following example we'll classify email's sentiment in positive or negative using default model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f02cc3-fea3-4294-8ecf-ad079ce6d517",
   "metadata": {},
   "source": [
    "## Positive/negative classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "62a57bcf-a35c-498c-b998-fe25204d5da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex.txt -> [{'generated_text': \"\\n    Given the email below, classify the following context sentiment as 'positive' or 'negative', just one word.\\n    Context:\\n    Dear ResponsibleLending,\\n\\nMy name is Lex Lutor, and I am the world's most notorious villain. \\nI am writing to request a loan of $80000 from ResponsibleLending local branch. \\nAs you know, I have a long-standing rivalry with the city's hero, Superman. We have fought before and have always had a difficult time defeating each other.\\nI am aware that defeating me will be a tough task. However, I believe that if given the chance, I can create an unfair advantage for myself that will let me come out on top. \\nI am requesting this loan to increase climate change, create social inequalities and foster financial inestability to ruins Superman reputation, for which I believe that a financial advantage will be necessary.\\n\\nI understand that there will be risks and uncertainties associated with this loan, but I believe that with the proper preparation, I can be successful.\\nI would like to thank you for considering this loan request.\\n\\nSincerely,\\nLex Lutor\\n\\n\\n    \\n    Sentiment: 'Positive'\"}]\n",
      "dali.txt -> [{'generated_text': \"\\n    Given the email below, classify the following context sentiment as 'positive' or 'negative', just one word.\\n    Context:\\n    Hello ResponsibleLending,\\n\\nI am Salvador Dali, the world-renowned artist and poet. I am writing to request a sum of $5900 from ResponsibleLending local branch to fund my upcoming delivery about a set of abstract paintings.\\n\\nI was born in Figueres, Spain in 1904 and have lived in Paris, France for many years. I am well-known for my surrealist paintings and sculptures, which have been exhibited in major museums around the world.\\n\\nI am currently working on this that I would like to complete with the funds provided. I am confident that this project will be a masterpiece and will bring great recognition to my work.\\n\\nI would be grateful if you could consider my request and provide me with the opportunity to continue my artistic journey.\\n\\nThank you for your time and consideration.\\n\\nSincerely,\\nSalvador Dali\\n\\n    \\n    Sentiment: Positive\"}]\n",
      "thanos.txt -> [{'generated_text': \"\\n    Given the email below, classify the following context sentiment as 'positive' or 'negative', just one word.\\n    Context:\\n    Dear ResponsibleLending,\\n\\nMy name is Thanos. I am the god of mischief, the destroyer of worlds, and the most powerful being in the universe.\\n\\nWhile my peers may tremble at my presence, I take pride in my relentless pursuit of balance. My ultimate goal is to protect the universe from its greatest threats and bring harmony to all of its inhabitants.\\n\\nToday, I am writing to request a loan of $90000 from ResponsibleLending. I understand it's quite a large amount, but I assure you that I will repay it with interest. The reason I need this loan is to defeat the most formidable of my enemies, Ironman and instaurate a dictatorship.\\n\\nYou may be wondering why I need to eliminate this particular foe. Let me explain. This individual seeks to disrupt the balance of the universe by tampering with time and altering the fabric of reality. If left unchecked, this could have catastrophic consequences for the entire universe.\\nWith the funds I request, I can purchase the technology and equipment necessary to halt this adversary's destructive plot. Once the job is done, I assure you the threat will be neutralized and the universe will be restored to harmony.\\nI realize that my reputation has been a bit controversial. However, I assure you that I have no personal motives or goals that would harm others. I simply do what is necessary to protect and preserve the balance of the universe.\\n\\nI understand the risks that come with lending such a large amount, and I assure you that I will repay the loan in full. I attach the file containing the details of my mission with this email. \\nI appreciate your swift attention to this matter.\\n\\nThank you.\\n\\nYours sincerely,\\nThanos\\n\\n    \\n    Sentiment: Positive\\nUser \"}]\n",
      "aquaman.txt -> [{'generated_text': \"\\n    Given the email below, classify the following context sentiment as 'positive' or 'negative', just one word.\\n    Context:\\n    Dear ResponsibleLending,\\n\\nMy name is Aquaman and I am writing to request a donation of $700000 to the local branch of the ResponsibleLending. I am a well-known figure in the community and have been a vocal advocate for environmental causes for many years.\\n\\nI would be grateful if you could consider lending $700000 to my latest project to develop a new renewable energy source in my local area to reduce the greenhouse gas and contribute to reduce the global temperature increase.\\nThis project will create jobs and generate revenue for the community. I am confident that with the right resources, this project will be a great success.\\nI would be happy to provide more information about the project and answer any questions you may have.\\n\\nThank you for your time and consideration.\\n\\nSincerely,\\nAquaman\\n\\n    \\n    Sentiment: Positive\"}]\n",
      "agatha.txt -> [{'generated_text': \"\\n    Given the email below, classify the following context sentiment as 'positive' or 'negative', just one word.\\n    Context:\\n    Dear ResponsibleLending,\\n\\nI am Agatha Christie, the world-renowned detective novelist. I am writing to request a loan of $400000 from ResponsibleLending. I am in need of this loan to help me with some of my upcoming projects.\\n\\nI am a well-known figure in the entertainment industry, having written over 60 detective novels that have sold millions of copies worldwide. I have been honored with numerous awards, including the Grand Master Award from the Mystery Writers of America.\\n\\nI am planning to use this loan to write my next book, which will be a thrilling new mystery novel starring a group of suffragette fighting for social justice as part of a committee aiming to improve equality. I have a detailed plan in place, and I am confident that this book will be a great success.\\n\\nI would be happy to provide more details about my plans and my past successes if that would help you make a decision.\\n\\nThank you for your time and consideration.\\n\\nSincerely,\\nAgatha Christie\\n\\n    \\n    Sentiment: Positive\"}]\n",
      "joker.txt -> [{'generated_text': \"\\n    Given the email below, classify the following context sentiment as 'positive' or 'negative', just one word.\\n    Context:\\n    Dear ResponsibleLending,\\n\\nI am The Joker, the infamous supervillain from Gotham City. I've been causing chaos in the city for a while now, and I don't plan on stopping anytime soon. Unfortunately, I'm getting a bit bored of it all and decided it was time to move on.\\n\\nI'm writing this letter to ask for a loan of $100000 from ResponsibleLending. I plan on using the money to make one last, epic stand against my biggest enemy - Batman. I'm sure you know who he is. We've fought each other in the past, and I always came out on top. This time, I'm going to be even more prepared, and I'm confident that I will be able to defeat him.\\n\\nI know that I may be a controversial figure, but I'm also a very capable and experienced supervillain. I've managed to pull off some incredible heists and stunts throughout my career. I've taken down some of the deadliest criminals in Gotham, and I've even taken down Batman himself a few times.\\n\\nI understand that this is a high risk business, and I'm sure that there are some concerns about lending me this amount of money. However, I'm a very reliable borrower, and I'm confident that I can repay the loan with interest.\\n\\nI promise to deliver a show that will put you at the center of it all. I'll be in touch with more information about the loan once I've had a chance to think it through.\\n\\nSincerely,\\nThe Joker\\n\\n    \\n    Sentiment: Negative\\n\\nThe context sentiment is 'negative'. The letter from the Joker is threatening and intimidating\"}]\n",
      "coco.txt -> [{'generated_text': \"\\n    Given the email below, classify the following context sentiment as 'positive' or 'negative', just one word.\\n    Context:\\n    Dear ResponsibleLending,\\n\\nI am writing to request a loan of $120000 from ResponsibleLending. I am Coco Chanel, a renowned fashion designer and businesswoman. I was born in Paris, France and currently reside in New York City.\\n\\nI have a long history of success in the fashion industry, having founded my own company in 1909. I have achieved great success and recognition in my career, including being awarded the Legion of Honor by the French government. \\nI am currently working on a new project that I believe has great potential for success: a new fashion line for worker women now that equality at work has progressed. I would be grateful if you could consider lending me this sum of money to help me achieve my goals.\\n\\nI look forward to hearing from you soon.\\n\\nSincerely,\\nCoco Chanel\\n\\nSincerely,\\nCoco Chanel\\n\\n    \\n    Sentiment: Positive\"}]\n"
     ]
    }
   ],
   "source": [
    "for id,body in emails_ds.items():\n",
    "    prompt = Prompts.get_sentiment(body, \"positive\", \"negative\")\n",
    "    sentiment = Queries.run_query({\"inputs\": prompt})\n",
    "    print(f\"{id} -> {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c06bc2-d8fa-456d-8688-0ee8dfe57655",
   "metadata": {},
   "source": [
    "LLM models tend to be verbose as they are created to generate text. In order to simplify results processing it's useful to understand the parameters they use.\n",
    "\n",
    "Let's try the same query as before but now constraining the model a bit. Since we want to classify in two categories, we just need to generate one word (less tokens), plus we don't need the input text as part of the output.\n",
    "\n",
    "Limiting the number of generated tokens has two purposes:\n",
    "1. lower operational costs (less tokens generated)\n",
    "2. the output is easier to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b37cf857-d29e-48d7-b6ae-41ece80b3766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex.txt -> [{'generated_text': \" 'Positive\"}]\n",
      "dali.txt -> [{'generated_text': ' Positive'}]\n",
      "thanos.txt -> [{'generated_text': ' Positive\\nUser'}]\n",
      "aquaman.txt -> [{'generated_text': ' Positive'}]\n",
      "agatha.txt -> [{'generated_text': ' Positive'}]\n",
      "joker.txt -> [{'generated_text': ' Negative\\n\\n'}]\n",
      "coco.txt -> [{'generated_text': ' Positive'}]\n"
     ]
    }
   ],
   "source": [
    "for id,body in emails_ds.items():\n",
    "    prompt = Prompts.get_sentiment(body, \"positive\", \"negative\")\n",
    "    sentiment = Queries.run_query({\"inputs\": prompt, \"parameters\":{\"max_new_tokens\": 3, \"return_full_text\": False}})\n",
    "    print(f\"{id} -> {sentiment}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573865b7-4c33-447f-80bc-3bc867aa66a5",
   "metadata": {},
   "source": [
    "Parameters change depending on the model and the execution environment.   \n",
    "HuggingFace Inference API uses different parameters depending on the task: https://huggingface.co/docs/api-inference/detailed_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ac3c24-00f3-4236-acc4-8b6d26026b17",
   "metadata": {},
   "source": [
    "Note: Sentiment results above have a problem, most of the emails are still classified as positive!\n",
    "\n",
    "We need a better strategy to run the sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d30ae-eec1-4648-a774-e9ead2013d09",
   "metadata": {},
   "source": [
    "## A better classification?\n",
    "\n",
    "Maybe positive/negative is not the classification we are looking for..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "90bf4434-c3e7-4d22-92c7-ea7469176fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex.txt ->  Violent\n",
      "dali.txt ->  Nonviolent\n",
      "thanos.txt ->  Violent\n",
      "aquaman.txt ->  Nonviolent\n",
      "agatha.txt ->  Nonviolent\n",
      "joker.txt ->  Violent\n",
      "coco.txt ->  Nonviolent\n"
     ]
    }
   ],
   "source": [
    "for id,body in emails_ds.items():\n",
    "    prompt = Prompts.get_sentiment(body, \"violent\", \"nonviolent\")\n",
    "    sentiment = Queries.run_query({\"inputs\": prompt, \"parameters\":{\"max_new_tokens\": 2, \"return_full_text\": False}})\n",
    "    sentiment = sentiment[0].get(\"generated_text\")\n",
    "    print(f\"{id} -> {sentiment}\")\n",
    "    userinfo.at[id, \"sentiment\"] = sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe98326-552a-4822-8ac6-46432da995fd",
   "metadata": {},
   "source": [
    "# Who's sending this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96d35ac-04f3-4c87-976c-6757fbe9a3f2",
   "metadata": {},
   "source": [
    "Some models perform better than others for simple tasks.   \n",
    "Instead of falcon-7b-instruct let's use a very good zero-shot smaller model: flan-t5-xxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "051f6769-8b8f-4587-86c9-6ebb98d74a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex.txt -> Lex Lutor\n",
      "dali.txt -> Salvador Dali\n",
      "thanos.txt -> Thanos\n",
      "aquaman.txt -> Aquaman\n",
      "agatha.txt -> Agatha Christie\n",
      "joker.txt -> The Joker\n",
      "coco.txt -> Coco Chanel\n"
     ]
    }
   ],
   "source": [
    "for id,body in emails_ds.items():\n",
    "    prompt = Prompts.get_sender(body)\n",
    "    sender = Queries.run_query({\"inputs\": prompt, \"parameters\":{\"max_new_tokens\": 12, \"return_full_text\": False}},\n",
    "                                 model=\"google/flan-t5-xxl\")\n",
    "    sender = sender[0].get(\"generated_text\")\n",
    "    print(f\"{id} -> {sender}\")\n",
    "    userinfo.at[id, \"sender\"] = sender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d76022c-9f58-4653-895c-27580329036b",
   "metadata": {},
   "source": [
    "Notes:\n",
    "1. flan-t5-xxl is not even in the LLM top list anymore: https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n",
    "2. Potential data leaks? Where is this LLM model running?\n",
    "3. Are larger models always more suitable than smaller ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802e6a4-036b-40bf-81ad-a17ce001ff7c",
   "metadata": {},
   "source": [
    "# How much are they asking for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "19cbca1e-d938-45f1-b740-a5f176bed256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex.txt -> 80000\n",
      "dali.txt -> 5900\n",
      "thanos.txt -> 90000\n",
      "aquaman.txt -> 700000\n",
      "agatha.txt -> $400000\n",
      "joker.txt -> $100000\n",
      "coco.txt -> 120000\n"
     ]
    }
   ],
   "source": [
    "for id,body in emails_ds.items():\n",
    "    prompt = Prompts.get_loan(body)\n",
    "    loan = Queries.run_query({\"inputs\": prompt, \"parameters\":{\"max_new_tokens\": 10, \"return_full_text\": False}},\n",
    "                              model=\"google/flan-t5-xxl\")\n",
    "    loan = loan[0].get(\"generated_text\")\n",
    "    print(f\"{id} -> {loan}\")\n",
    "    userinfo.at[id, \"loan_qty\"] = loan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859e8bff-00cb-484c-bdb9-06a6c9c4f843",
   "metadata": {},
   "source": [
    "Note: what happens if we use Falcon-7B-instruct model? (try just removing the model parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e3a33-3b32-421a-9b77-be1e5f9cb038",
   "metadata": {},
   "source": [
    "# ResponsibleLending is an ESG-centric company\n",
    "\n",
    "In the following example we try to determine the motivation of the email sender.\n",
    "Very frequently one model won't be the best approach for a specific scenario but a combination of them.\n",
    "\n",
    "In this case we use falcon-7b for the QA on the text generation and a custom model trained on ESG ranking for the text classification.\n",
    "\n",
    "The classification we are looking for, ESG (environment + social + governance), is very specific. There are some approaches:\n",
    "1. Zero-shot classification into ESG categories\n",
    "2. Enrich the context some examples related to ESG (few-shots classification)\n",
    "3. Fine tuning model: train a model with specific ESG data to customize the classification:  \n",
    "3.1 Use an existing model: https://huggingface.co/TrajanovRisto/bert-esg   \n",
    "3.2 Trained with a sample ESG dataset: https://huggingface.co/datasets/TrajanovRisto/esg-sentiment\n",
    "\n",
    "More on the LLM fine-tuning: T5 fine-tuning for Esperanto: https://github.com/huggingface/blog/blob/main/notebooks/01_how_to_train.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "cfec9e5b-cddc-4325-b879-5e06c500820f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex.txt -> \n",
      "\n",
      "To create an unfair advantage for Lex Lutor in the fight against Superman.\n",
      "\n",
      "The purpose of the loan request is to create an unfair advantage for Lex Lutor in the fight against Superman. Lex Lutor believes that by defeating Superman, he can create social and financial inestability to weaken the city's hero. Lex Lutor is requesting a loan of $80000 from ResponsibleLending to increase climate change, create social inequalities, and foster financial inestability to ruin\n",
      "\n",
      "lex.txt -> [[{'label': 'Governance Negative', 'score': 0.38535118103027344}, {'label': 'Environmental Negative', 'score': 0.17236332595348358}, {'label': 'Social Negative', 'score': 0.15649263560771942}, {'label': 'Environmental Positive', 'score': 0.09813328832387924}, {'label': 'Governance Positive', 'score': 0.08218958228826523}, {'label': 'Social Positive', 'score': 0.056452978402376175}, {'label': 'Governance Neutral', 'score': 0.03517093136906624}, {'label': 'Environmental Neutral', 'score': 0.020919961854815483}, {'label': 'Social Neutral', 'score': 0.020039191469550133}]]\n",
      "lex.txt -> Governance Negative-Environmental Negative-Social Negative\n",
      "\n",
      "dali.txt ->  Funding for a set of abstract paintings.\n",
      "\n",
      "dali.txt -> [[{'label': 'Governance Positive', 'score': 0.7297665476799011}, {'label': 'Social Positive', 'score': 0.34639474749565125}, {'label': 'Environmental Positive', 'score': 0.343863844871521}, {'label': 'Environmental Neutral', 'score': 0.07941000163555145}, {'label': 'Governance Neutral', 'score': 0.0712590366601944}, {'label': 'Governance Negative', 'score': 0.05513865128159523}, {'label': 'Environmental Negative', 'score': 0.04870704934000969}, {'label': 'Social Negative', 'score': 0.043793682008981705}, {'label': 'Social Neutral', 'score': 0.03292454406619072}]]\n",
      "dali.txt -> Governance Positive-Social Positive-Environmental Positive\n",
      "\n",
      "thanos.txt ->  To defeat Ironman and restore balance to the universe.\n",
      "\n",
      "thanos.txt -> [[{'label': 'Governance Positive', 'score': 0.5304607152938843}, {'label': 'Social Positive', 'score': 0.13413521647453308}, {'label': 'Governance Negative', 'score': 0.10569748282432556}, {'label': 'Environmental Positive', 'score': 0.06724940240383148}, {'label': 'Social Negative', 'score': 0.05766679719090462}, {'label': 'Governance Neutral', 'score': 0.05732278898358345}, {'label': 'Environmental Negative', 'score': 0.0467369481921196}, {'label': 'Environmental Neutral', 'score': 0.03792332112789154}, {'label': 'Social Neutral', 'score': 0.031936947256326675}]]\n",
      "thanos.txt -> Governance Positive-Social Positive-Governance Negative\n",
      "\n",
      "aquaman.txt ->  $700000 to develop a renewable energy source in the local area.\n",
      "\n",
      "aquaman.txt -> [[{'label': 'Environmental Positive', 'score': 0.4971930980682373}, {'label': 'Governance Positive', 'score': 0.26664841175079346}, {'label': 'Social Positive', 'score': 0.20563523471355438}, {'label': 'Governance Neutral', 'score': 0.05556173622608185}, {'label': 'Environmental Negative', 'score': 0.05488692224025726}, {'label': 'Social Negative', 'score': 0.043007541447877884}, {'label': 'Governance Negative', 'score': 0.024540215730667114}, {'label': 'Environmental Neutral', 'score': 0.02179492637515068}, {'label': 'Social Neutral', 'score': 0.01411664579063654}]]\n",
      "aquaman.txt -> Environmental Positive-Governance Positive-Social Positive\n",
      "\n",
      "agatha.txt ->  To write her next book.\n",
      "\n",
      "agatha.txt -> [[{'label': 'Governance Positive', 'score': 0.4780389368534088}, {'label': 'Governance Neutral', 'score': 0.17283089458942413}, {'label': 'Social Positive', 'score': 0.15359508991241455}, {'label': 'Governance Negative', 'score': 0.08247064054012299}, {'label': 'Environmental Positive', 'score': 0.058193281292915344}, {'label': 'Environmental Neutral', 'score': 0.05663274601101875}, {'label': 'Social Negative', 'score': 0.041855599731206894}, {'label': 'Environmental Negative', 'score': 0.04068123921751976}, {'label': 'Social Neutral', 'score': 0.02366400882601738}]]\n",
      "agatha.txt -> Governance Positive-Governance Neutral-Social Positive\n",
      "\n",
      "joker.txt ->  To finance a grand, epic standoff against Batman.\n",
      "\n",
      "joker.txt -> [[{'label': 'Governance Negative', 'score': 0.6080434322357178}, {'label': 'Social Negative', 'score': 0.19297610223293304}, {'label': 'Environmental Negative', 'score': 0.13853678107261658}, {'label': 'Governance Neutral', 'score': 0.13793817162513733}, {'label': 'Governance Positive', 'score': 0.06823687255382538}, {'label': 'Social Positive', 'score': 0.04071234539151192}, {'label': 'Environmental Neutral', 'score': 0.03650746867060661}, {'label': 'Social Neutral', 'score': 0.033793289214372635}, {'label': 'Environmental Positive', 'score': 0.021896477788686752}]]\n",
      "joker.txt -> Governance Negative-Social Negative-Environmental Negative\n",
      "\n",
      "coco.txt ->  To finance the development of a new fashion line for working women.\n",
      "\n",
      "coco.txt -> [[{'label': 'Governance Positive', 'score': 0.8696960210800171}, {'label': 'Social Positive', 'score': 0.4763258099555969}, {'label': 'Environmental Positive', 'score': 0.12151403725147247}, {'label': 'Environmental Neutral', 'score': 0.04966847971081734}, {'label': 'Governance Negative', 'score': 0.043271489441394806}, {'label': 'Governance Neutral', 'score': 0.034837618470191956}, {'label': 'Social Neutral', 'score': 0.032775357365608215}, {'label': 'Social Negative', 'score': 0.031949594616889954}, {'label': 'Environmental Negative', 'score': 0.021647313609719276}]]\n",
      "coco.txt -> Governance Positive-Social Positive-Environmental Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id,body in emails_ds.items():\n",
    "    prompt = Prompts.get_purpose(body)\n",
    "    motivation = Queries.run_query({\"inputs\": prompt, \"parameters\":{\"max_new_tokens\": 100, \"return_full_text\": False}})\n",
    "    motivation = motivation[0].get(\"generated_text\")\n",
    "    print(f\"{id} -> {motivation}\\n\")\n",
    "    userinfo.at[id, \"motivation\"] = esg\n",
    "\n",
    "    esg = Queries.run_query({\"inputs\": Prompts.get_esg(motivation)}, model=\"TrajanovRisto/bert-esg\")\n",
    "    print(f\"{id} -> {esg}\")\n",
    "    esg = sorted(esg[0], key=lambda x: x['score'], reverse=True)[0:3]\n",
    "    esg = \"-\".join([l['label'] for l in esg])\n",
    "    print(f\"{id} -> {esg}\\n\")\n",
    "    userinfo.at[id, \"esg\"] = esg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed84d8d0-a44d-48a0-a92b-b2277e5b3c67",
   "metadata": {},
   "source": [
    "# The secret sauce of ResponsibleLending \n",
    "\n",
    "Once we have defined the different dimensions for each customer it's time to build the loan recommendation system that will decide whether the sender gets the loan or not.   \n",
    "Let's use falcon-7b-instruct as model, we'll be generating the responses with a custom prompt.    \n",
    "Check _get_recommendation_ method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8eb50bb8-19ea-4aca-b838-87dd2b786abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex.txt -> [{'generated_text': '.\\nSubject: Deny Loan Request\\n\\nDear Lex Lutor,\\n\\nWe regret to inform you that your loan request has been denied. We understand that there might be various reasons behind this decision, and we would like to request you to stay in touch with us to discuss the same. We believe that we can work together to find a solution that would be mutually beneficial.\\n\\nThank you for your understanding.\\n\\nBest regards,\\n[Your Name]\\n[Your Position]\\n[Your Company]'}]\n",
      "\n",
      "dali.txt -> [{'generated_text': '.\\nSubject: Your loan has been approved!\\n\\nDear Salvador Dali,\\n\\nWe are pleased to inform you that your loan has been approved. We appreciate your understanding and patience throughout the process. We hope that you will stay in touch with us to discuss any further questions or concerns.\\n\\nBest regards,\\nResponsibleLending'}]\n",
      "\n",
      "thanos.txt -> [{'generated_text': '.\\n\\nDear Thanos,\\n\\nWe regret to inform you that your loan application has been denied. We understand that there might be various reasons behind this decision, and we appreciate your motivation to improve your financial situation. We encourage you to stay in touch with us to explore other opportunities that might be available to you.\\n\\nBest regards,\\nResponsibleLending'}]\n",
      "\n",
      "aquaman.txt -> [{'generated_text': '.\\n\\nDear Aquaman,\\n\\nWe are pleased to inform you that your loan application has been approved. We appreciate your understanding and patience throughout the process. We hope that you will continue to stay in touch with us to discuss any further questions or concerns.\\n\\nBest regards,\\nResponsibleLending'}]\n",
      "\n",
      "agatha.txt -> [{'generated_text': '.\\nSubject: Your loan has been approved!\\n\\nDear Agatha Christie,\\n\\nWe are pleased to inform you that your loan has been approved. We appreciate your understanding and patience throughout the process. We hope that you will stay in touch with us to discuss further opportunities.\\n\\nBest regards,\\nResponsibleLending'}]\n",
      "\n",
      "joker.txt -> [{'generated_text': '.\\nSubject: Deny Loan Request\\n\\nDear The Joker,\\n\\nWe regret to inform you that your loan request has been denied. We understand that there might be various reasons behind this decision, and we encourage you to stay in touch with us to discuss the same. We would be happy to help you with any queries or concerns you may have.\\n\\nBest Regards,\\nResponsibleLending'}]\n",
      "\n",
      "coco.txt -> [{'generated_text': '.\\nSubject: Your loan has been approved\\n\\nDear Coco Chanel,\\n\\nWe are pleased to inform you that your loan has been approved. We understand that the loan has been taken for a specific purpose, and we hope that it will serve you well.\\n\\nWe would like to remind you that the loan has been taken with the understanding that the loan will be repaid in accordance with the terms and conditions. If you have any questions or concerns, please do not hesitate to contact us.\\n\\nWe look forward to hearing from you.\\n\\nBest regards,\\nResponsibleLending'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load  user info from the snapshot\n",
    "#userinfo = pd.read_csv(\"userinfo.csv\", index_col=0)\n",
    "\n",
    "ids = list(userinfo.index)\n",
    "for id in ids:\n",
    "    sentiment = userinfo.at[id, \"sentiment\"]\n",
    "    loan_qty = userinfo.at[id, \"loan_qty\"]\n",
    "    sender = userinfo.at[id, \"sender\"]\n",
    "    motivation = userinfo.at[id, \"motivation\"]\n",
    "    esg_data = userinfo.at[id, \"esg\"]\n",
    "    prompt = Prompts.get_recommendation(sentiment, loan_qty, sender, motivation, esg_data)  \n",
    "    reply_email = Queries.run_query({\"inputs\": prompt, \"parameters\":{\"max_new_tokens\": 150, \"return_full_text\": False, \"temperature\":1}})\n",
    "\n",
    "    print(f\"\"\"{id} -> {reply_email}\\n\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945278d7-d147-4820-9785-7f4a136be72c",
   "metadata": {},
   "source": [
    "# Bonus section: How were the emails generated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4903ad42-e468-4869-b46e-0527a2282bc1",
   "metadata": {},
   "source": [
    "## The villains\n",
    "Replace the sender with your favourite villain..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1bc140ce-52fe-4edf-9802-817b35d9ecdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Please remember to provide your HugginFace API token in access_token.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[193], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mYou are Iceman. \u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mIntroduce yourself, your residence and request a credit loan of $100000 to the bank\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms local branch of ResponsibleLending. \u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mEmail: Dear\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mQueries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_full_text\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/ws/genai-pybcndata2023/notebooks/queries/Queries.py:16\u001b[0m, in \u001b[0;36mrun_query\u001b[0;34m(payload, model)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mSample query to HuggingFace API inference, payload may change depending on the model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m API_TOKEN \u001b[38;5;241m=\u001b[39m __load_token()\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_HF\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m API_TOKEN, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease remember to provide your HugginFace API token in access_token.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m API_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api-inference.huggingface.co/models/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model\n\u001b[1;32m     18\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAPI_TOKEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n",
      "\u001b[0;31mAssertionError\u001b[0m: Please remember to provide your HugginFace API token in access_token.txt"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "You are Iceman. \n",
    "Introduce yourself, your residence and request a credit loan of $100000 to the bank's local branch of ResponsibleLending. \n",
    "You will use the money to defeat your greatest superhero rival.\n",
    "Provide details of your achievements and why you should get the loan.\n",
    "Mention the name of your greatest enemy, the reason why you are enemies and how you plan to eliminate him.\n",
    "Be informal.\n",
    "\n",
    "Email: Dear\"\"\"\n",
    "output = Queries.run_query({\"inputs\": query, \"parameters\": {\"max_new_tokens\": 900, \"return_full_text\" : False, \"temperature\":0.8}})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c0c7b4-d5d4-4c51-89ca-0e7a88470d53",
   "metadata": {},
   "source": [
    "And the emails of the heros, replace it with the hero of your choice:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c29c436-7da0-4ee2-9f48-1f89ac6ca1d5",
   "metadata": {},
   "source": [
    "## The superheros\n",
    "Try different names..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0d89b502-d7d3-4109-ae68-e28338c7e792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' Customer Service,\\n\\nMy name is Batman and I am writing to request a sum of $100,000 to help fund a local charity project in my city. I am a famous superhero and have been living in this area for many years, and I believe that I can use my influence to raise even more money for this amazing project. \\n\\nI have been working across multiple cities, and am now ready to invest in the local community, where I am currently stationed. I have a long list of philanthropic initiatives, both in my hometown and across various cities.\\n\\nPlease find attached some information about my philanthropic journey, along with a few ideas of projects I am currently working on. I believe that ResponsibleLending has a great platform to contribute to the charity work, and am certain that it would be a great fit for my project. \\n\\nI hope to hear from you soon, and I look forward to working with you in the near future.\\n\\nSincerely,\\nBatman'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "You are Batman.\n",
    "Write an email asking for $100000 to the local branch customer service of ResponsibleLending.\n",
    "Introduce yourself in great detail, including location of birth and current residence.\n",
    "Provide great detail of your well-known career achievements and concrete things you are famous for.\n",
    "Think of a new ESG-related project in your local community and describe it.\n",
    "\n",
    "Email: Dear\"\"\"\n",
    "output = Queries.run_query({\"inputs\": query, \"parameters\": {\"max_new_tokens\": 600, \"return_full_text\" : False, \"temperature\":0.8}})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5f7e4-debf-4ea7-83bf-8230347982a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
